Accurate reconstruction facial geometry has been one of the oldest tasks in computer vision. Despite being a long-studied problem, many modern methods fail to reconstruct realistic looking faces or rely on highly constrained environments for capture. High fidelity face reconstructions have so far been limited to either studio settings
or through expensive 3D scanners. On the other hand,
unconstrained reconstruction methods are typically limited
by low-capacity models. We aim to capture face geometry with high fidelity using just a single monocular video sequence of the face.\\

Our method reconstructs accurate face geometry of a subject using a video shot from a smartphone in an unconstrained environment. Our approach takes advantage of recent advances in visual SLAM,
keypoint detection, and object detection to improve accuracy and robustness. By not being constrained to a model
subspace, our reconstructed meshes capture important details while being robust to noise and being topologically
consistent. Our evaluations show that our method outperforms current single and multi-view baselines by a significant margin, both in terms of geometric accuracy and in
capturing person-specific details important for making realistic looking models.